{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JRKhyTIdg0p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Nd1yc06gdri3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/Lecture_series/')\n",
        "!ls"
      ],
      "metadata": {
        "id": "nbAqMQiIdwOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Bfha9zftdwL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category = df['Category'].value_counts().reset_index()\n",
        "category"
      ],
      "metadata": {
        "id": "Jgv8biuCdwJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=category['Category'], y=category['index'], palette='cool')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7sC8t-kMdwFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.pie(category['Category'], labels=category['index'],\n",
        "        colors=sns.color_palette('cool'), autopct='%.0f%%')\n",
        "plt.title('Category Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LupHIbPLdwDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanResume(resumeText):\n",
        "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
        "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
        "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
        "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
        "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
        "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
        "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
        "    return resumeText"
      ],
      "metadata": {
        "id": "AYeiurGqdwBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned'] = df['Resume'].apply(lambda x:cleanResume(x))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nw2oJ4-Rdv_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the entire resume text\n",
        "corpus=\" \"\n",
        "for i in range(0,len(df)):\n",
        "    corpus= corpus+ df[\"cleaned\"][i]"
      ],
      "metadata": {
        "id": "hyEk9QlYdv82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "YPGMZnh6dv6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
        "#Tokenizing the text\n",
        "tokens = tokenizer.tokenize(corpus)\n",
        "len(tokens)"
      ],
      "metadata": {
        "id": "5i7mdlNhdv0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we shall make everything lowercase for uniformity\n",
        "#to hold the new lower case words\n",
        "words = []\n",
        "# Looping through the tokens and make them lower case\n",
        "for word in tokens:\n",
        "    words.append(word.lower())\n",
        "words[0:5]"
      ],
      "metadata": {
        "id": "A3KhFkpDeIn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now encode the data\n",
        "label = LabelEncoder()\n",
        "df['new_Category'] = label.fit_transform(df['Category'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "b2pDb-_XeLJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df['new_Category'])"
      ],
      "metadata": {
        "id": "yruGsWUqeLGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the cleaned columns\n",
        "text = df['cleaned'].values\n",
        "target = df['new_Category'].values\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    stop_words='english',\n",
        "    max_features=1500)\n",
        "word_vectorizer.fit(text)\n",
        "WordFeatures = word_vectorizer.transform(text)"
      ],
      "metadata": {
        "id": "mTQL1pkleLEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WordFeatures.shape"
      ],
      "metadata": {
        "id": "a_nwqKhjeLBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(WordFeatures, target, random_state=24, test_size=0.2)"
      ],
      "metadata": {
        "id": "-h4bFS1KeTaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "OLcYQytCeTXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "model = OneVsRestClassifier(KNeighborsClassifier())\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xM8l86RReXhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "19PR06l9eXfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'---------------------------------\\n| Training Accuracy   :- {(model.score(X_train, y_train)*100).round(2)}% |')\n",
        "print(f'---------------------------------\\n| Validation Accuracy :- {(model.score(X_test, y_test)*100).round(2)}% |\\n---------------------------------')"
      ],
      "metadata": {
        "id": "5zVpWpkbeXaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_test, y_test))"
      ],
      "metadata": {
        "id": "Rtravx-UeXVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stop words are generally the most common words in a language.\n",
        "#English stop words from nltk.\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "words_new = []\n",
        "#Now we need to remove the stop words from the words variable\n",
        "#Appending to words_new all words that are in words but not in sw\n",
        "for word in words:\n",
        "    if word not in stopwords:\n",
        "        words_new.append(word)"
      ],
      "metadata": {
        "id": "PGlpakWceXSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_new[0:5]"
      ],
      "metadata": {
        "id": "2XKITNLzehrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  import nltk\n",
        "  nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "oLG8nY2xehov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "wn = WordNetLemmatizer() \n",
        "lem_words=[]\n",
        "for word in words_new:\n",
        "    word=wn.lemmatize(word)\n",
        "    lem_words.append(word)"
      ],
      "metadata": {
        "id": "KC4t6Z3yehlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lem_words[0:5]"
      ],
      "metadata": {
        "id": "WbAMtWREehh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same=0\n",
        "diff=0\n",
        "for i in range(0,1832):\n",
        "    if(lem_words[i]==words_new[i]):\n",
        "        same=same+1\n",
        "    elif(lem_words[i]!=words_new[i]):\n",
        "        diff=diff+1\n",
        "print('Number of words Lemmatized=', diff)\n",
        "print('Number of words not Lemmatized=', same)"
      ],
      "metadata": {
        "id": "lISm-L5rehec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The frequency distribution of the words\n",
        "freq_dist = nltk.FreqDist(lem_words)\n",
        "#Frequency Distribution Plot\n",
        "plt.subplots(figsize=(20,12))\n",
        "freq_dist.plot(30)"
      ],
      "metadata": {
        "id": "Nu39kcctesDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we generate wordcloud\n",
        "res=' '.join([i for i in lem_words if not i.isdigit()])"
      ],
      "metadata": {
        "id": "hRRLs5O-evLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(16,10))\n",
        "wordcloud = WordCloud(\n",
        "                          background_color='black',\n",
        "                          max_words=100,\n",
        "                          width=1400,\n",
        "                          height=1200\n",
        "                         ).generate(res)\n",
        "plt.imshow(wordcloud)\n",
        "plt.title('Resume Text WordCloud (100 Words)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-6xEtufEevIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(16,10))\n",
        "wordcloud = WordCloud(\n",
        "                          background_color='black',\n",
        "                          max_words=200,\n",
        "                          width=1400,\n",
        "                          height=1200\n",
        "                         ).generate(res)\n",
        "plt.imshow(wordcloud)\n",
        "plt.title('Resume Text WordCloud (200 Words)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F1IVyDulevEU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}